---
description: 
globs: 
alwaysApply: true
---
# Supabase Local & Remote Database Workflow

## Current Setup Overview

### Local Environment
- **Project ID:** npcvbxrshuflujcnikon
- **Environment:** Docker-based Supabase setup
- **Database Connection:** `postgresql://postgres:postgres@localhost:54322/postgres`
- **API Endpoint:** http://127.0.0.1:54321
- **Supabase Studio:** http://127.0.0.1:54323
- **Email Testing:** http://127.0.0.1:54324

### Remote Environment
- **Project ID:** npcvbxrshuflujcnikon
- **Project Reference:** npcvbxrshuflujcnikon
- **Database Connection:** Managed by Supabase
- **API Endpoint:** https://npcvbxrshuflujcnikon.supabase.co

## Identified Issues & Best Practices

### Issues We've Encountered

1. **Migration Naming Inconsistency**
   - Files not following timestamp convention (`<timestamp>_name.sql`)
   - Manual fixes needed for migration history

2. **Local-Remote Discrepancies**
   - Cron jobs and edge functions may exist in production but not locally
   - RLS policies may differ between environments
   - Database schemas get out of sync

3. **Direct Database Modifications**
   - Changes made directly in Supabase Studio or SQL Editor bypass migration tracking
   - Hard to replicate these changes in local environment

4. **Environment Variable Management**
   - Different values needed for local vs. remote development
   - Credentials and secrets management

5. **Authentication URL Handling**
   - Redirect URLs may work differently in local vs production
   - Email testing setup requires special handling locally

## 1. Development Workflow

### A. Environment Setup

1. **Required Environment Variables:**
   ```bash
   # In .env.local (for local development)
   NEXT_PUBLIC_SUPABASE_URL=http://127.0.0.1:54321
   NEXT_PUBLIC_SUPABASE_ANON_KEY=your-local-anon-key
   # Database password for CLI operations with remote
   SUPABASE_DB_PASSWORD=your-remote-db-password
   
   # In .env.production (for production)
   NEXT_PUBLIC_SUPABASE_URL=https://npcvbxrshuflujcnikon.supabase.co
   NEXT_PUBLIC_SUPABASE_ANON_KEY=your-production-anon-key
   ```

2. **Switching Between Environments:**
   ```json
   // In package.json scripts
   "scripts": {
     "dev": "next dev",
     "dev:local": "cp .env.local.backup .env.local && next dev",
     "dev:prod": "cp .env.local .env.local.backup && cp .env.production .env.local && next dev",
     "dev:reset": "cp .env.local.backup .env.local"
   }
   ```

3. **Client Configuration:**
   ```typescript
   // Validate URL format for both local and production
   if (!supabaseUrl || !(supabaseUrl.startsWith('https://') || 
                          supabaseUrl.startsWith('http://127.0.0.1'))) {
     throw new Error('Invalid or missing NEXT_PUBLIC_SUPABASE_URL')
   }
   ```

### B. Starting a New Feature

1. **Always start with a fresh sync:**
   ```bash
   # Link to remote project first
   export SUPABASE_DB_PASSWORD=$(grep SUPABASE_DB_PASSWORD .env.local | cut -d= -f2-)
   supabase link --project-ref npcvbxrshuflujcnikon
   
   # Ensure local is up-to-date with remote
   supabase db pull
   
   # Verify migration state
   supabase migration list
   ```

2. **Create feature branch:**
   ```bash
   git checkout -b feature/your-feature-name
   ```

3. **Create new migrations for schema changes:**
   ```bash
   # Using the timestamp format YYYYMMDDHHMMSS
   touch supabase/migrations/$(date +%Y%m%d%H%M%S)_descriptive_name.sql
   ```

### C. Testing Locally

1. **Apply migrations to local DB:**
   ```bash
   # Either directly with psql
   PGPASSWORD=postgres psql -h localhost -p 54322 -U postgres -d postgres -f supabase/migrations/your_migration.sql
   
   # Or using Supabase CLI
   supabase migration up
   ```

2. **Create seed data for testing:**
   ```bash
   # Create a seed file if needed
   touch supabase/seed.sql
   
   # Apply seed data
   PGPASSWORD=postgres psql -h localhost -p 54322 -U postgres -d postgres -f supabase/seed.sql
   ```

3. **Test changes with Next.js:**
   ```bash
   npm run dev
   ```

4. **Test functionality that works differently in local:**
   
   - **Auth Flow:** Test at http://127.0.0.1:54324 for email verification
   - **Cron Jobs:** Consider manually triggering functions
     ```sql
     -- Manual test of cron functions
     SELECT public.your_cron_function();
     ```
   - **Turnstile/CAPTCHA:** Use test keys for local environment
     ```
     # Test keys for Cloudflare Turnstile
     Site Key: 1x00000000000000000000AA
     Secret Key: 1x0000000000000000000000000000000AA
     ```

### D. Committing Changes

1. **Always commit migration files with related code:**
   ```bash
   git add supabase/migrations/your_migration.sql
   git add related/code/files.ts
   git commit -m "feat: descriptive message about your changes"
   ```

## 2. Special Considerations

### A. Cron Jobs & Edge Functions

**Key Issue:** Cron jobs set up in production won't automatically sync to local.

**Solution:**
1. **Always include cron jobs in migration files:**
   ```sql
   -- Example migration including a cron job
   CREATE OR REPLACE FUNCTION public.my_scheduled_function() 
   RETURNS void AS $$
   BEGIN
     -- Function logic here
   END;
   $$ LANGUAGE plpgsql;
   
   -- Drop existing schedule first to avoid errors
   SELECT cron.unschedule('job-name');
   
   -- Create the cron job
   SELECT cron.schedule(
     'job-name',
     '0 0 * * *', -- Schedule (daily at midnight)
     'SELECT public.my_scheduled_function()'
   );
   ```

2. **Document all cron jobs in a central place:**
   Create a `CRON-JOBS.md` file documenting all scheduled jobs.

3. **API Dependencies in Cron Jobs:**
   - Make external API calls resilient with fallbacks
   - Handle API rate limits and errors gracefully
   - Test API calls manually in local environment

### B. Authentication & Redirects

**Key Issue:** Auth redirects behave differently between environments.

**Solution:**
1. **Implement robust auth callback handling:**
   ```typescript
   // In auth callback route
   export async function GET(request: Request) {
     try {
       const requestUrl = new URL(request.url)
       const code = requestUrl.searchParams.get('code')
       const token = requestUrl.searchParams.get('token')
       const next = requestUrl.searchParams.get('next') ?? '/dashboard'
     
       const cookieStore = cookies()
       const supabase = createRouteHandlerClient({ cookies: () => cookieStore })
     
       // Handle both token and code for flexibility
       if (token) {
         await supabase.auth.verifyOtp({
           token_hash: token,
           type: 'email',
         })
         console.log('Auth verification successful with token')
       } else if (code) {
         await supabase.auth.exchangeCodeForSession(code)
         console.log('Auth verification successful with code')
       }
     
       // URL to redirect to after sign in process completes
       return NextResponse.redirect(new URL(next, requestUrl.origin))
     } catch (error) {
       console.error('Auth callback error:', error)
       return NextResponse.redirect(new URL('/auth/sign-in', request.url))
     }
   }
   ```

2. **Direct dashboard redirects for magic links:**
   ```typescript
   // In auth provider
   const signInWithMagicLink = async (email: string, captchaToken?: string) => {
     // Direct redirect to dashboard is more reliable
     const redirectUrl = `${window.location.origin}/dashboard`;
     
     const { error } = await supabase.auth.signInWithOtp({
       email,
       options: {
         emailRedirectTo: redirectUrl,
         captchaToken
       },
     })
   }
   ```

### C. RLS Policies

**Key Issue:** RLS policies may differ between environments.

**Solution:**
1. **Always include complete RLS setup in migrations:**
   ```sql
   -- Drop existing policies first to avoid errors
   DROP POLICY IF EXISTS "policy_name" ON table_name;
   
   -- Create new policy
   CREATE POLICY "policy_name" 
   ON table_name
   FOR SELECT 
   TO authenticated
   USING (auth.uid() = user_id);
   ```

2. **Test RLS thoroughly in local environment:**
   ```bash
   # Using direct SQL to test policy with different users
   PGPASSWORD=postgres psql -h localhost -p 54322 -U postgres -d postgres -c "
   -- Set session to simulate authenticated user
   SET LOCAL role = 'authenticated';
   SET LOCAL request.jwt.claims = '{\"sub\": \"test-user-id\"}';
   
   -- Test query
   SELECT * FROM your_table;
   "
   ```

## 3. Deployment Process

### A. Testing Before Deployment

1. **Create a fresh local instance to verify migrations:**
   ```bash
   supabase stop
   supabase start
   ```

2. **Apply all migrations:**
   ```bash
   supabase migration up
   ```

3. **Verify application works with fresh DB instance.**

### B. Deploying to Remote

1. **Link to remote project (if not already):**
   ```bash
   # Set password from environment variable
   export SUPABASE_DB_PASSWORD=$(grep SUPABASE_DB_PASSWORD .env.local | cut -d= -f2-)
   
   # Link project
   supabase link --project-ref npcvbxrshuflujcnikon
   ```

2. **Check migration status:**
   ```bash
   # See pending migrations
   supabase migration list --linked
   ```

3. **Push migrations to remote:**
   ```bash
   supabase db push
   ```

4. **Verify remote deployment:**
   - Test the deployed application with production DB
   - Check cron job execution with alerts or logs

## 4. Troubleshooting Common Issues

### A. Migration History Issues

**Problem:** Migration history out of sync.
**Solution:**
```bash
# Check migration state
supabase migration list

# Repair specific migrations
supabase migration repair --status applied 20240430000001
```

### B. Local Database Reset

**Problem:** Local database in bad state.

**Solution:**
```bash
# Reset entirely
supabase db reset

# Pull fresh from remote
supabase db pull
```

### C. Database Connection Issues

**Problem:** Cannot connect to database.

**Solution:**
```bash
# Check if docker containers are running
docker ps | grep supabase

# Restart if needed
supabase stop
supabase start
```

### D. Authentication Issues

**Problem:** Magic links or redirects not working.

**Solution:**
```bash
# Check email service for local testing
open http://127.0.0.1:54324

# Ensure callback URL is correct
# For local: http://localhost:3000/auth/callback?next=/dashboard
# For prod: https://yourdomain.com/auth/callback?next=/dashboard
```

## 5. Advanced Tips

### A. Database Snapshots

Create regular snapshots before major changes:
```bash
# Backup local database
PGPASSWORD=postgres pg_dump -h localhost -p 54322 -U postgres postgres > backup_$(date +%Y%m%d).sql
```

### B. Reverting Migrations

Always include a way to revert changes:
```sql
-- Migration to add a column
ALTER TABLE your_table ADD COLUMN new_column TEXT;

-- How to revert (in comments or separate file)
-- ALTER TABLE your_table DROP COLUMN new_column;
```

### C. Testing API Dependencies

For functions relying on external APIs (e.g., price feeds):
```sql
-- Test API functions manually
SELECT public.update_fear_greed_index();
SELECT public.fetch_and_update_btc_spot_price();

-- Check results
SELECT * FROM public.spot_price ORDER BY date DESC LIMIT 5;
SELECT * FROM public.fear_greed_index ORDER BY date DESC LIMIT 5;
```

## Remember

1. **Never make direct changes to the production database** without corresponding migrations
2. **Always test migrations locally** before applying to production
3. **Keep local and remote in sync** to avoid surprises during deployment
4. **Document all cron jobs and edge functions** for better maintenance
5. **Use version control for all database changes** through migration files
6. **Handle authentication and API dependencies with fallbacks**
7. **Test both local and production environments before deploying**
